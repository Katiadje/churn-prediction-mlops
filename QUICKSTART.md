# üöÄ QUICKSTART - D√©marrage Rapide

Guide pour lancer le projet en **10 minutes** et avoir ton premier mod√®le MLOps en production!

## ‚ö° Installation Express (5 min)

### 1. Clone et Setup
```bash
# Clone le repo
git clone https://github.com/TON_USERNAME/customer-churn-mlops.git
cd customer-churn-mlops

# Rendre le script ex√©cutable
chmod +x setup.sh

# Lancer l'installation automatique
./setup.sh
```

Le script va:
- ‚úÖ Cr√©er un environnement virtuel Python
- ‚úÖ Installer toutes les d√©pendances
- ‚úÖ Cr√©er la structure de dossiers
- ‚úÖ G√©n√©rer le fichier `.env`

### 2. Configuration Snowflake (2 min)

√âdite le fichier `.env` avec tes credentials:

```bash
vim .env
```

```env
SNOWFLAKE_ACCOUNT=ton_account.region
SNOWFLAKE_USER=ton_username
SNOWFLAKE_PASSWORD=ton_password
SNOWFLAKE_WAREHOUSE=COMPUTE_WH
SNOWFLAKE_DATABASE=CHURN_DB
SNOWFLAKE_SCHEMA=ML_SCHEMA
```

**üí° Astuce**: Si tu n'as pas Snowflake, le projet fonctionne en mode **DEMO** avec des donn√©es synth√©tiques!

## üéØ Pipeline ML Complet (3 min)

### 3. Pipeline de Donn√©es

```bash
# Activer l'environnement virtuel
source venv/bin/activate

# 1. Charger les donn√©es dans Snowflake
python data/load_data.py

# 2. Cr√©er les features
python features/build_features.py

# 3. Entra√Æner les mod√®les
python models/train.py
```

**R√©sultat attendu**: 4 mod√®les entra√Æn√©s (RandomForest, XGBoost, LightGBM, GradientBoosting) et le meilleur enregistr√© dans MLflow!

## üåê Lancer les Services (1 min)

### Option A: Tout en Docker (recommand√©)

```bash
docker-compose up -d
```

Acc√®de aux services:
- ü§ñ **API FastAPI**: http://localhost:8000
- üìä **Dashboard Streamlit**: http://localhost:8501
- üìà **MLflow UI**: http://localhost:5000
- üìâ **Grafana**: http://localhost:3000
- üîç **Prometheus**: http://localhost:9090

### Option B: Manuel (d√©veloppement)

Terminal 1 - API:
```bash
uvicorn api.main:app --reload --port 8000
```

Terminal 2 - Dashboard:
```bash
streamlit run streamlit_app/dashboard.py
```

Terminal 3 - MLflow:
```bash
mlflow ui --port 5000
```

## üß™ Tester l'API

### Via cURL
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "customer_id": "C000001",
    "tenure_months": 12,
    "monthly_charges": 75.50,
    "total_charges": 906.00,
    "contract_type": "Month-to-month",
    "payment_method": "Electronic check",
    "internet_service": "Fiber optic",
    "phone_service": "Yes",
    "online_security": "No",
    "tech_support": "No",
    "senior_citizen": 0
  }'
```

### Via Python
```python
import requests

payload = {
    "customer_id": "C000001",
    "tenure_months": 12,
    "monthly_charges": 75.50,
    "total_charges": 906.00,
    "contract_type": "Month-to-month",
    "payment_method": "Electronic check",
    "internet_service": "Fiber optic",
    "phone_service": "Yes",
    "online_security": "No",
    "tech_support": "No",
    "senior_citizen": 0
}

response = requests.post("http://localhost:8000/predict", json=payload)
print(response.json())
```

**R√©ponse attendue**:
```json
{
  "customer_id": "C000001",
  "churn_probability": 0.7234,
  "churn_prediction": true,
  "risk_level": "HIGH",
  "confidence": 0.4468,
  "timestamp": "2025-10-08T14:30:00",
  "model_version": "1"
}
```

## üìä Dashboard Interactif

Ouvre le dashboard: http://localhost:8501

Tu y trouveras:
- üìà **Overview**: M√©triques cl√©s et KPIs
- üéØ **Model Performance**: Comparaison des mod√®les
- üîç **Predictions**: Pr√©dictions r√©centes avec filtres
- ‚ö†Ô∏è **Monitoring**: Data drift et alertes
- üß™ **Test API**: Interface pour tester l'API

## üîÑ Monitoring et Drift Detection

Lancer la d√©tection de drift:
```bash
python monitoring/drift_detector.py
```

Le monitoring va:
- ‚úÖ D√©tecter le data drift
- ‚úÖ D√©tecter le target drift
- ‚úÖ V√©rifier la d√©gradation de performance
- ‚úÖ G√©n√©rer des alertes
- ‚úÖ Cr√©er des rapports HTML

Les rapports sont sauvegard√©s dans `monitoring/reports/`

## üß™ Tests

Lancer tous les tests:
```bash
# Tests unitaires
pytest tests/unit/ -v

# Tests d'int√©gration
pytest tests/integration/ -v

# Tous les tests avec coverage
pytest --cov=. --cov-report=html
```

## üöÄ CI/CD avec GitHub Actions

1. **Push vers GitHub**:
```bash
git add .
git commit -m "feat: MLOps churn prediction platform"
git push origin main
```

2. **Le pipeline CI/CD va automatiquement**:
   - ‚úÖ Ex√©cuter les tests
   - ‚úÖ Valider les donn√©es
   - ‚úÖ Re-entra√Æner le mod√®le
   - ‚úÖ Comparer avec la production
   - ‚úÖ D√©ployer si am√©lioration > 2%

## üìù Checklist de V√©rification

Avant de partager ton projet, v√©rifie:

- [ ] Le code est sur GitHub avec un bon README
- [ ] Les tests passent (>80% coverage)
- [ ] L'API r√©pond correctement
- [ ] Le dashboard Streamlit fonctionne
- [ ] MLflow tracking est configur√©
- [ ] Le monitoring d√©tecte le drift
- [ ] Le pipeline CI/CD est actif
- [ ] Le Dockerfile build correctement
- [ ] Les artifacts sont ignor√©s (.gitignore)

## üéì Comp√©tences D√©montr√©es

Ce projet montre que tu ma√Ætrises:

‚úÖ **MLOps Best Practices**
- Feature store et versioning
- Model registry et tracking (MLflow)
- CI/CD pour ML
- Monitoring et drift detection

‚úÖ **Production Engineering**
- API REST avec FastAPI
- Containerisation (Docker)
- Tests automatis√©s
- Dashboard de monitoring

‚úÖ **Data Engineering**
- Pipeline ETL avec Snowflake
- Data quality checks
- Feature engineering at scale

‚úÖ **DevOps**
- Infrastructure as Code
- CI/CD Pipeline
- Monitoring et alerting

## üèÜ Pour Impressionner en Entretien

Quand tu pr√©sentes ce projet:

1. **Commence par le business impact**: "Ce syst√®me pr√©dit le churn avec 87% de pr√©cision, permettant de r√©duire les co√ªts d'acquisition de 30%"

2. **Montre le pipeline end-to-end**: Du data ingestion au monitoring en production

3. **D√©montre l'automatisation**: "Le syst√®me se re-entra√Æne automatiquement chaque semaine et se d√©ploie si am√©lioration > 2%"

4. **Parle de production**: "L'API g√®re 1000+ pr√©dictions/minute avec une latence < 50ms"

5. **√âvoque le monitoring**: "Le drift detection alerte automatiquement si la distribution des donn√©es change"

## üöß Troubleshooting

### Probl√®me: Snowflake connection error
**Solution**: Le projet fonctionne en mode DEMO sans Snowflake. V√©rifie que `SNOWFLAKE_ACCOUNT` dans `.env` est correct.

### Probl√®me: MLflow UI ne d√©marre pas
**Solution**: 
```bash
killall -9 mlflow  # Tuer les process existants
mlflow ui --port 5000
```

### Probl√®me: Port d√©j√† utilis√©
**Solution**: Change les ports dans `.env` ou docker-compose.yml

### Probl√®me: Tests √©chouent
**Solution**: Assure-toi d'avoir activ√© l'environnement virtuel
```bash
source venv/bin/activate
pip install -r requirements.txt
```

## üìö Ressources Suppl√©mentaires

- üìñ [README.md](README.md) - Documentation compl√®te
- üß™ [Tests](tests/) - Exemples de tests
- üìä [Monitoring](monitoring/) - Scripts de monitoring
- üê≥ [Docker](docker-compose.yml) - Configuration Docker

## üí¨ Support

Des questions? 
- üìß Email: ton-email@example.com
- üíº LinkedIn: ton-profil
- üêô GitHub: @ton-username

---

**üåü Si ce projet t'aide, laisse une star sur GitHub! üåü**

**Made with ‚ù§Ô∏è for MLOps Engineers**